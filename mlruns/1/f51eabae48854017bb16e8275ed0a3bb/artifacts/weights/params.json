{
  "per_device_train_batch_size": 1,
  "gradient_accumulation_steps": 4,
  "num_train_epochs": 5,
  "learning_rate": 0.0002,
  "logging_steps": 5,
  "save_strategy": "no",
  "fp16": true,
  "bf16": false,
  "max_new_tokens": 384,
  "do_sample": false,
  "prompt_length": 512,
  "torch_dtype": "torch.float16",
  "min_pixels": 200704,
  "max_pixels": 401408,
  "kv_cache": true,
  "quantize": false
}