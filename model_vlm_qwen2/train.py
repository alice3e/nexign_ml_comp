import os
import torch
from transformers import (
    Qwen2VLForConditionalGeneration, 
    TrainingArguments, 
    Trainer,
    AutoProcessor # –î–æ–±–∞–≤–∏–ª–∏ –∏–º–ø–æ—Ä—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
)
from peft import LoraConfig, get_peft_model, TaskType
from dataset import BPMNDataset, collate_fn

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
MODEL_ID = "Qwen/Qwen2-VL-2B-Instruct"
# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞–ø–∫—É, —á—Ç–æ–±—ã app.py –∏ inference.py –≤–∏–¥–µ–ª–∏ –≤–µ—Å–∞
OUTPUT_DIR = os.path.join("model_vlm_qwen2", "weights") 
DATA_DIR = "data"

def train():
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {MODEL_ID}...")
    
    # 0. –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (—á—Ç–æ–±—ã –ø–æ—Ç–æ–º –µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å)
    processor = AutoProcessor.from_pretrained(MODEL_ID, min_pixels=256*28*28, max_pixels=512*28*28)

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        MODEL_ID,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    )
    model.gradient_checkpointing_enable()
    
    # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA (–£–õ–£–ß–®–ï–ù–ù–ê–Ø)
    peft_config = LoraConfig(
        r=16, # –†–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü—ã
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        # –í–ê–ñ–ù–û: –û–±—É—á–∞–µ–º –í–°–ï –ª–∏–Ω–µ–π–Ω—ã–µ —Å–ª–æ–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ attention. 
        # –≠—Ç–æ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —É–º—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á–∞—Ö.
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        task_type="CAUSAL_LM",
    )
    
    model = get_peft_model(model, peft_config)
    print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
    model.print_trainable_parameters()

    # 3. –î–∞–Ω–Ω—ã–µ
    train_dataset = BPMNDataset(
        os.path.join(DATA_DIR, "train.jsonl"), 
        os.path.join(DATA_DIR, "images"), 
        MODEL_ID
    )
    
    # 4. –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è (–°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï)
    args = TrainingArguments(
        output_dir="checkpoints_temp", # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤
        per_device_train_batch_size=1, 
        gradient_accumulation_steps=4, # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –ø–æ–±–æ–ª—å—à–µ (—Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç)
        num_train_epochs=5,            # 5 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç–ø–æ—Ö –ª—É—á—à–µ, —á–µ–º 10 –±—ã—Å—Ç—Ä—ã—Ö
        learning_rate=2e-4,            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π LR, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ª–æ–º–∞–µ—Ç –≤–µ—Å–∞
        logging_steps=5,
        save_strategy="no",            # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ, —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª
        fp16=False,
        bf16=True,
        use_cpu=False,
        optim="adamw_torch",
        remove_unused_columns=False,
        report_to="none"
    )

    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=train_dataset,
        data_collator=collate_fn,
    )

    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    trainer.train()
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {OUTPUT_DIR}...")
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ—Ç
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–¥–∞–ø—Ç–µ—Ä—ã
    model.save_pretrained(OUTPUT_DIR)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
    processor.save_pretrained(OUTPUT_DIR)
    
    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–π inference.py")

if __name__ == "__main__":
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
    train()