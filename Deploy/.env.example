# Конфигурация для docker-compose

# VLM Inference Service
BASE_MODEL_ID=Qwen/Qwen3-VL-2B-Instruct
DEVICE=cpu  # Измените на 'cuda' для GPU или 'mps' для Apple Silicon
TORCH_DTYPE=float16
MAX_NEW_TOKENS=384

# Backend API
REQUEST_TIMEOUT=120

# Порты (если нужно изменить)
# FRONTEND_PORT=8501
# BACKEND_PORT=8000
# VLM_PORT=8002
# ADAPTER_PORT=8001
# DB_PORT=8003